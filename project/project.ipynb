{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Итоговый проект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:49:21.607018Z",
     "start_time": "2020-05-22T15:49:02.504316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/jpype/_core.py:209: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from os import listdir\n",
    "import codecs\n",
    "import pickle                                                                   \n",
    "from bs4 import BeautifulSoup as BS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from boilerpipe.extract import Extractor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:49:21.756516Z",
     "start_time": "2020-05-22T15:49:21.609456Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_groups.csv',dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:49:21.926440Z",
     "start_time": "2020-05-22T15:49:21.763077Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):                                                       \n",
    "    with open(name + '.pkl', 'wb') as f:                                        \n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)                            \n",
    "                                                                                \n",
    "def load_obj(name ):                                                            \n",
    "    with open(name + '.pkl', 'rb') as f:                                        \n",
    "        return pickle.load(f)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T12:32:59.541241Z",
     "start_time": "2020-05-22T12:32:59.465619Z"
    }
   },
   "outputs": [],
   "source": [
    "#START HEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:49:45.801103Z",
     "start_time": "2020-05-22T15:49:45.798463Z"
    }
   },
   "outputs": [],
   "source": [
    "name = 'NumWordsRulesExtractor'\n",
    "name = 'train_data'+name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:08.388450Z",
     "start_time": "2020-05-22T15:49:46.058548Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = load_obj(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:08.717594Z",
     "start_time": "2020-05-22T15:50:08.390486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv', encoding = 'UTF-8') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:08.923894Z",
     "start_time": "2020-05-22T15:50:08.728559Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_titles = []\n",
    "for id in train_data.doc_id.values:\n",
    "    doc_titles.append(doc_to_title[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:09.008689Z",
     "start_time": "2020-05-22T15:50:08.926060Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['title'] = doc_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:09.091385Z",
     "start_time": "2020-05-22T15:50:09.014397Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_splits(data,n=3):\n",
    "    bound =[]\n",
    "    max_group = data.group_id.max()\n",
    "    bound.extend([i*int(max_group/n)+1 for i in range(1,n)])\n",
    "    bound.append(max_group+1)\n",
    "    prev_id = 1\n",
    "    for group_id in bound:\n",
    "        yield (data[~((prev_id <= data.group_id) & (data.group_id < group_id))].pair_id.values-1,\n",
    "            data[(prev_id <= data.group_id) & (data.group_id < group_id)].pair_id.values-1)\n",
    "        prev_id = group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:09.175825Z",
     "start_time": "2020-05-22T15:50:09.093040Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()#max_features = 70)\n",
    "#texts_vectorized = vectorizer.fit_transform(train_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:09.262562Z",
     "start_time": "2020-05-22T15:50:09.177777Z"
    }
   },
   "outputs": [],
   "source": [
    "#texts_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:09.514890Z",
     "start_time": "2020-05-22T15:50:09.270496Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:10.188833Z",
     "start_time": "2020-05-22T15:50:09.521657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "groups_one_hot = OneHotEncoder().fit_transform(train_data.group_id.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:10.198195Z",
     "start_time": "2020-05-22T15:50:10.192247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 129)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:10.315292Z",
     "start_time": "2020-05-22T15:50:10.200040Z"
    }
   },
   "outputs": [],
   "source": [
    "#texts_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:10.407329Z",
     "start_time": "2020-05-22T15:50:10.317534Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:10.552304Z",
     "start_time": "2020-05-22T15:50:10.415170Z"
    }
   },
   "outputs": [],
   "source": [
    "#features = hstack( [texts_vectorized,groups_one_hot] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:10.700207Z",
     "start_time": "2020-05-22T15:50:10.555798Z"
    }
   },
   "outputs": [],
   "source": [
    "target = train_data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T14:02:28.454527Z",
     "start_time": "2020-05-22T14:02:28.383150Z"
    }
   },
   "outputs": [],
   "source": [
    "#doc_id = train_data.doc_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:10.856960Z",
     "start_time": "2020-05-22T15:50:10.703326Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = train_data.group_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:11.553765Z",
     "start_time": "2020-05-22T15:50:10.862965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1, ..., 129, 129, 129], dtype=int16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T15:50:13.231215Z",
     "start_time": "2020-05-22T15:50:11.558681Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T17:17:45.848981Z",
     "start_time": "2020-05-22T17:14:10.045512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe68493cca643c189df51c6b48781cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "for group in tqdm(set(groups)):\n",
    "    elements_in_same_group = train_data[train_data.group_id == group].pair_id.values-1\n",
    "    vectorizer.fit(train_data.title[elements_in_same_group] +train_data.text[elements_in_same_group])\n",
    "    texts_vectorized_titles = vectorizer.transform(train_data.title[elements_in_same_group])\n",
    "    texts_vectorized_titles = scaler.fit_transform(texts_vectorized_titles)\n",
    "    \n",
    "    texts_vectorized_texts = vectorizer.transform(train_data.text[elements_in_same_group])\n",
    "    texts_vectorized_texts = scaler.fit_transform(texts_vectorized_texts)\n",
    "\n",
    "    #dist_matr = pairwise_distances(texts_vectorized.tocsr()[elements_in_same_group], texts_vectorized.tocsr()[elements_in_same_group], metric = 'cosine')\n",
    "    dist_matr = pairwise_distances(texts_vectorized_titles, texts_vectorized_titles, metric = 'cosine')\n",
    "    dist_matr2 = pairwise_distances(texts_vectorized_texts, texts_vectorized_texts, metric = 'cosine')\n",
    "    dist_matr3 = pairwise_distances(texts_vectorized_texts, texts_vectorized_titles, metric = 'cosine')\n",
    "    #print(texts_vectorized.shape)\n",
    "    #clustering = DBSCAN(eps = 0.5, min_samples=3).fit(dist_matr)\n",
    "    dist_matr_sorted = np.sort(dist_matr,axis=1)[:,0:21][:,::-1]\n",
    "    dist_matr_sorted2 = np.sort(dist_matr2,axis=1)[:,0:21][:,::-1]\n",
    "    dist_matr_sorted3 = np.sort(dist_matr3,axis=1)[:,0:21][:,::-1]\n",
    "    mean_dist = dist_matr.mean(axis = 1)\n",
    "    dist_matr_sorted = np.hstack((dist_matr_sorted, mean_dist.reshape(-1,1)))\n",
    "    dist_matr_sorted = np.hstack((dist_matr_sorted, dist_matr_sorted2))\n",
    "    dist_matr_sorted = np.hstack((dist_matr_sorted, dist_matr_sorted3))\n",
    "\n",
    "#    dist_matr_sorted = hstack((dist_matr_sorted, texts_vectorized))\n",
    "    \n",
    "    if group == 1 :\n",
    "        features_by_dist =  dist_matr_sorted\n",
    "    else:\n",
    "        features_by_dist = vstack((features_by_dist, dist_matr_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T17:17:45.855468Z",
     "start_time": "2020-05-22T17:17:45.851043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_by_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T17:17:45.970467Z",
     "start_time": "2020-05-22T17:17:45.859134Z"
    }
   },
   "outputs": [],
   "source": [
    "features_by_dist = hstack([features_by_dist, groups_one_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T17:17:58.010845Z",
     "start_time": "2020-05-22T17:17:45.973740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.coo.coo_matrix'>\n",
      "[0.7205815538391639]\n",
      "<class 'scipy.sparse.coo.coo_matrix'>\n",
      "[0.7205815538391639, 0.690319310694374]\n",
      "<class 'scipy.sparse.coo.coo_matrix'>\n",
      "[0.7205815538391639, 0.690319310694374, 0.7282463186077645]\n",
      "0.7130490610471009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "max_score = 0\n",
    "scores = []\n",
    "for train, test in get_splits(train_data,n=3):\n",
    "            print(type(features_by_dist))\n",
    "            model = RandomForestClassifier(n_jobs=6,n_estimators=200)\n",
    "            model.fit(features_by_dist.tocsr()[train], target[train])\n",
    "            pred = (model.predict(features_by_dist.tocsr()[test]))               \n",
    "            scores.append(f1_score(pred,target[test]))\n",
    "            print(scores)\n",
    "print(sum(scores)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "402px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
